{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d120d45f",
   "metadata": {},
   "source": [
    "## Metrics used in evaluations\n",
    "\n",
    "References:\n",
    "- https://www.geeksforgeeks.org/f1-score-in-machine-learning/\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303a5d30",
   "metadata": {},
   "source": [
    "### Precision\n",
    "- Emphasizes Quality - it measures the accuracy of the positive predictions\n",
    "- `TruePositives / (TruePositives + FalsePositives)`\n",
    "\n",
    "### Recall\n",
    "- Emphasizes Quantity - how well the model captures all relevant instances\n",
    "- `TruePositives / (TruePositives + FalseNegatives)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "773b1645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.83\n",
      "Recall: 1.00\n"
     ]
    }
   ],
   "source": [
    "text1 = \"The cat sat on the mat.\"\n",
    "text2 = \"The cat sat on the big mat.\"\n",
    "\n",
    "split = lambda t: set(t.lower().split())\n",
    "\n",
    "word_set1 = split(text1)\n",
    "word_set2 = split(text2)\n",
    "\n",
    "true_positives = len(word_set1.intersection(word_set2))\n",
    "false_positives = len(word_set2 - word_set1)\n",
    "false_negatives = len(word_set1 - word_set2)\n",
    "\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84bb5cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['cat', 'sat', 'big', 'the', 'on', 'mat.']\n",
      "Binarized text1: [1 1 0 1 1 1]\n",
      "Binarized text2: [1 1 1 1 1 1]\n",
      "Precision: 0.83\n",
      "Recall: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Calculating precision and recall using sklearn\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "vocabulary = list(word_set1.union(word_set2))\n",
    "mlb = MultiLabelBinarizer(classes=vocabulary)  # Binarize the texts: presence (1) or absence (0) of words\n",
    "print(f\"Classes: {mlb.classes}\")\n",
    "\n",
    "binary_text1 = mlb.fit_transform([word_set1])[0]\n",
    "binary_text2 = mlb.fit_transform([word_set2])[0]\n",
    "print(f\"Binarized text1: {binary_text1}\")\n",
    "print(f\"Binarized text2: {binary_text2}\")\n",
    "\n",
    "precision = precision_score(binary_text1, binary_text2)\n",
    "recall = recall_score(binary_text1, binary_text2)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d330a1",
   "metadata": {},
   "source": [
    "### F1 score\n",
    "- The F1 Score is the harmonic mean of precision and recall, providing a balance between the two, especially when they are in conflict.\n",
    "- `TruePositives / (TruePositives + FalseNegatives)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41819ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.91\n",
      "F1 score: 0.91\n"
     ]
    }
   ],
   "source": [
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "print(f\"F1 score: {f1_score(binary_text1, binary_text2):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442d9290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (openai)",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
